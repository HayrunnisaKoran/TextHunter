"""
Sadece AI Verilerini Ãœretme Scripti (Optimize EdilmiÅŸ Versiyon)
- Mevcut human_abstracts.json dosyasÄ±nÄ± okur
- Gemini AI ile 3000 AI yazÄ±mÄ± metin Ã¼retir
- Stabilite iÃ§in worker sayÄ±sÄ± dÃ¼ÅŸÃ¼rÃ¼ldÃ¼ ve bekleme sÃ¼releri optimize edildi
"""

import os
import json
import time
import pandas as pd
from datetime import datetime
from tqdm import tqdm
import google.generativeai as genai
from typing import List, Dict
from concurrent.futures import ThreadPoolExecutor
import threading
import random

# Ã–zel Exception sÄ±nÄ±fÄ±
class QuotaExceededException(Exception):
    """API quota limiti aÅŸÄ±ldÄ±ÄŸÄ±nda fÄ±rlatÄ±lÄ±r"""
    pass

# --- YAPILANDIRMA (KRÄ°TÄ°K AYARLAR) ---
AI_COUNT = 3000
OUTPUT_DIR = "../Data/raw"
INPUT_FILE = os.path.join(OUTPUT_DIR, "human_abstracts.json")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
CHECKPOINT_FILE = os.path.join(OUTPUT_DIR, "ai_abstracts_checkpoint.json")

# OPTÄ°MÄ°ZASYON AYARLARI
# Yeni API anahtarÄ± kullanÄ±yorsanÄ±z daha hÄ±zlÄ± toplama yapabilirsiniz
MAX_WORKERS = 1  # 1 thread - kota limitlerini Ã¶nlemek iÃ§in (en gÃ¼venli)
CHECKPOINT_INTERVAL = 10 # Veri kaybÄ±nÄ± Ã¶nlemek iÃ§in daha sÄ±k kayÄ±t

# HIZ AYARLARI (Yeni API anahtarÄ± iÃ§in optimize edildi)
# Gemini API limitleri: ~15 istek/dakika (Ã¼cretsiz), ~60 istek/dakika (Ã¼cretli)
# GÃ¼venli deÄŸer: 10 saniye (6 istek/dakika) - quota limitinden uzak kalÄ±r
# Agresif deÄŸer: 5 saniye (12 istek/dakika) - daha hÄ±zlÄ± ama riskli
MIN_REQUEST_INTERVAL = 10.0  # 10 saniye (yeni API iÃ§in gÃ¼venli ve hÄ±zlÄ±)
# EÄŸer hala quota hatasÄ± alÄ±rsanÄ±z: 15.0 veya 20.0 yapÄ±n
# EÄŸer hiÃ§ hata almÄ±yorsanÄ±z: 5.0 veya 7.0'ye dÃ¼ÅŸÃ¼rebilirsiniz 

def load_human_abstracts() -> List[Dict]:
    if not os.path.exists(INPUT_FILE):
        print(f"âš  UYARI: {INPUT_FILE} dosyasÄ± bulunamadÄ±!")
        return []
    
    print(f"Mevcut human verileri yÃ¼kleniyor: {INPUT_FILE}")
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        human_data = json.load(f)
    print(f"âœ“ {len(human_data)} adet human verisi yÃ¼klendi")
    return human_data

def generate_single_ai_text(model, prompt: str, lock: threading.Lock, last_request_time: List[float], 
                            min_interval: float) -> Dict:
    """
    Tek bir AI metni Ã¼retir. Hata durumunda Ã¼stel bekleme (Exponential Backoff) uygular.
    """
    max_retries = 5
    base_wait_time = 5 # Ä°lk hata beklemesi 5 saniye
    
    for attempt in range(max_retries):
        try:
            # --- Rate Limiting (HÄ±z KontrolÃ¼) ---
            with lock:
                current_time = time.time()
                time_since_last = current_time - last_request_time[0]
                
                # EÄŸer son istekten beri yeterince zaman geÃ§mediyse bekle
                if time_since_last < min_interval:
                    sleep_needed = min_interval - time_since_last
                    time.sleep(sleep_needed)
                
                # Ä°steÄŸi yapmadan hemen Ã¶nce zamanÄ± gÃ¼ncelle
                last_request_time[0] = time.time()

            # API Ã§aÄŸrÄ±sÄ±
            response = model.generate_content(prompt)
            
            if not response or not hasattr(response, 'text'):
                raise ValueError("BoÅŸ yanÄ±t")
            
            generated_text = response.text.strip()
            
            # Basit kalite kontrolÃ¼
            if len(generated_text) < 50:
                raise ValueError("Ã‡ok kÄ±sa metin")

            return {
                "text": generated_text,
                "label": "AI",
                "source": "gemini",
                "prompt": prompt,
                "generated_date": datetime.now().isoformat()
            }

        except Exception as e:
            error_msg = str(e).lower()
            
            # 429 veya Quota hatasÄ± tespiti
            is_rate_limit = "429" in error_msg or "quota" in error_msg or "resource exhausted" in error_msg
            
            if attempt < max_retries - 1:
                if is_rate_limit:
                    # Quota hatasÄ± alÄ±ndÄ± - Ã¶zel exception fÄ±rlat
                    raise QuotaExceededException("API quota limiti aÅŸÄ±ldÄ±")
                else:
                    # DiÄŸer hatalar iÃ§in daha kÄ±sa bekleme
                    wait_time = (base_wait_time * (2 ** attempt)) + random.uniform(0, 2)
                    wait_time = min(wait_time, 30)  # Max 30 saniye
                    print(f"\nâš  Hata: {str(e)[:50]}... - {int(wait_time)}sn bekleniyor.")
                
                time.sleep(wait_time)
                continue
            
            return None # TÃ¼m denemeler baÅŸarÄ±sÄ±z
    return None

def generate_ai_texts(count: int = 3000, api_key: str = "", max_workers: int = 2) -> List[Dict]:
    if not api_key:
        print("âŒ HATA: GEMINI_API_KEY eksik!")
        return []
    
    print(f"\n{'='*60}")
    print(f"Gemini AI ile {count} metin Ã¼retiliyor (STABIL MOD)")
    print(f"{'='*60}\n")
    
    genai.configure(api_key=api_key)
    
    # Ã–nce API'den mevcut modelleri al
    available_models = []
    print("Mevcut modeller kontrol ediliyor...")
    try:
        models = genai.list_models()
        for m in models:
            if 'generateContent' in m.supported_generation_methods:
                short_name = m.name.replace('models/', '')
                available_models.append(short_name)
        if available_models:
            print(f"âœ“ {len(available_models)} model bulundu")
    except Exception as e:
        print(f"âš  Model listesi alÄ±namadÄ±: {str(e)[:100]}")
    
    # Ã–ncelik sÄ±ralamasÄ± - Ã¶nce gÃ¼ncel modeller, sonra eski modeller
    priority_models = [
        'gemini-2.5-flash',      # En yeni ve hÄ±zlÄ±
        'gemini-2.0-flash',       # 2.0 Flash
        'gemini-2.5-pro',         # En yeni Pro
        'gemini-2.0-pro',         # 2.0 Pro
        'gemini-1.5-flash',       # Eski ama stabil
        'gemini-1.5-pro',         # Eski Pro
        'gemini-pro-latest',      # Latest versiyon
        'gemini-pro'              # Genel
    ]
    
    # Ã–nce mevcut modellerden Ã¶ncelikli olanlarÄ± bul
    model_to_try = []
    if available_models:
        # Ã–ncelik sÄ±rasÄ±na gÃ¶re mevcut modellerden seÃ§
        for preferred in priority_models:
            matching = [m for m in available_models if preferred in m.lower()]
            if matching:
                model_to_try.extend(matching)
        # EÄŸer hiÃ§biri bulunamadÄ±ysa, flash iÃ§eren modelleri, sonra diÄŸerlerini ekle
        if not model_to_try:
            flash_models = [m for m in available_models if 'flash' in m.lower()]
            if flash_models:
                model_to_try.extend(flash_models)
            else:
                model_to_try.extend(available_models[:3])  # Ä°lk 3 modeli dene
    else:
        # API'den liste alÄ±namadÄ±ysa, Ã¶ncelik listesini kullan
        model_to_try = priority_models
    
    model = None
    selected_model_name = ""
    
    print("Uygun model aranÄ±yor...")
    for m_name in model_to_try:
        try:
            temp_model = genai.GenerativeModel(m_name)
            # Test isteÄŸi
            test_response = temp_model.generate_content("Hi")
            if test_response and hasattr(test_response, 'text'):
                model = temp_model
                selected_model_name = m_name
                print(f"âœ“ Model seÃ§ildi: {selected_model_name}")
                break
        except Exception as e:
            print(f"  - {m_name} kullanÄ±lamadÄ± ({str(e)[:50]}...)")
            continue
            
    if not model:
        print("âŒ HiÃ§bir model Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±. API Key veya KotanÄ±zÄ± kontrol edin.")
        print("\nÃ‡Ã¶zÃ¼m Ã¶nerileri:")
        print("1. API anahtarÄ±nÄ±zÄ±n geÃ§erli olduÄŸundan emin olun")
        print("2. Mevcut modelleri gÃ¶rmek iÃ§in: python list_gemini_models.py")
        print("3. Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin")
        return []

    # Prompt ÅŸablonlarÄ±
    prompts = [
        "Write a detailed academic abstract about machine learning applications in natural language processing. 150-300 words.",
        "Write a comprehensive academic abstract about deep learning models for computer vision. 150-300 words.",
        "Write an academic abstract about statistical methods in data science. 150-300 words.",
        "Write a detailed academic abstract about neural network architectures for time series. 150-300 words.",
        "Write a comprehensive academic abstract about reinforcement learning algorithms. 150-300 words.",
        "Write an academic abstract about transformer models and LLMs. 150-300 words.",
        "Write a detailed academic abstract about unsupervised learning clustering. 150-300 words."
    ]
    
    # Thread senkronizasyonu iÃ§in
    lock = threading.Lock()
    last_request_time = [0.0] # List kullanarak referans ile geÃ§iyoruz
    
    # Checkpoint yÃ¼kle
    ai_texts = load_checkpoint()
    start_index = len(ai_texts)
    
    # Duplicate kontrolÃ¼ iÃ§in mevcut metinleri set'e al (hÄ±zlÄ± arama iÃ§in)
    # Bu sayede yeni API key ile bile veri tekrarÄ± olmaz
    existing_texts = set()
    for item in ai_texts:
        if 'text' in item:
            # Metni normalize et (baÅŸlangÄ±Ã§/son boÅŸluklarÄ± temizle)
            normalized_text = item['text'].strip()
            if normalized_text:
                existing_texts.add(normalized_text)
    
    if existing_texts:
        print(f"âœ“ {len(existing_texts)} adet mevcut veri duplicate kontrolÃ¼ iÃ§in hazÄ±rlandÄ±")
    
    print(f"\nBaÅŸlangÄ±Ã§: {start_index}/{count}")
    print(f"Worker SayÄ±sÄ±: {max_workers}")
    print(f"Ä°stek AralÄ±ÄŸÄ±: {MIN_REQUEST_INTERVAL} saniye (KotayÄ± korumak iÃ§in)")
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        from concurrent.futures import as_completed
        
        future_to_idx = {}
        retry_queue = []  # BaÅŸarÄ±sÄ±z olanlarÄ± tekrar denemek iÃ§in
        completed_count = start_index
        last_save_count = len(ai_texts)
        
        # Ä°lk batch'i gÃ¶nder (sadece worker sayÄ±sÄ± kadar)
        next_index = start_index
        batch_size = max_workers * 2  # Her seferinde 2x worker kadar gÃ¶rev gÃ¶nder
        
        def submit_batch(start_idx, end_idx):
            """Bir batch gÃ¶rev gÃ¶nder"""
            for i in range(start_idx, min(end_idx, count)):
                p_idx = i % len(prompts)
                future = executor.submit(
                    generate_single_ai_text, 
                    model, 
                    prompts[p_idx], 
                    lock, 
                    last_request_time, 
                    MIN_REQUEST_INTERVAL
                )
                future_to_idx[future] = i
        
        # Ä°lk batch'i gÃ¶nder
        submit_batch(next_index, next_index + batch_size)
        next_index += batch_size
        
        # SonuÃ§larÄ± topla
        quota_exceeded = False  # Quota hatasÄ± flag'i
        with tqdm(total=count, initial=start_index, desc="AI Ãœretimi") as pbar:
            while completed_count < count and not quota_exceeded:
                # Tamamlanan gÃ¶revleri kontrol et
                for future in list(future_to_idx.keys()):
                    if future.done():
                        idx = future_to_idx.pop(future)
                        try:
                            result = future.result()
                            
                            if result:
                                # Duplicate kontrolÃ¼ - aynÄ± metin zaten varsa ekleme
                                # Bu sayede yeni API key ile bile veri tekrarÄ± olmaz
                                result_text = result.get('text', '').strip()
                                if result_text and result_text not in existing_texts:
                                    ai_texts.append(result)
                                    existing_texts.add(result_text)  # Set'e ekle (gelecek kontroller iÃ§in)
                                    completed_count += 1
                                    pbar.update(1)
                                    
                                    # DÃ¼zenli KayÄ±t
                                    if len(ai_texts) - last_save_count >= CHECKPOINT_INTERVAL:
                                        save_checkpoint(ai_texts)
                                        last_save_count = len(ai_texts)
                                        pbar.set_postfix({"Kaydedilen": len(ai_texts), "BaÅŸarÄ±sÄ±z": len(retry_queue)})
                                else:
                                    # Duplicate bulundu - retry queue'ya ekle (yeni veri Ã¼retmek iÃ§in)
                                    if result_text in existing_texts:
                                        pbar.set_postfix({"Kaydedilen": len(ai_texts), "Duplicate": 1})
                                    retry_queue.append(idx)
                                    completed_count += 1
                                    pbar.update(1)
                            else:
                                # BaÅŸarÄ±sÄ±z - retry queue'ya ekle
                                retry_queue.append(idx)
                                completed_count += 1
                                pbar.update(1)
                        except QuotaExceededException:
                            # Quota hatasÄ± - tÃ¼m iÅŸlemi durdur
                            quota_exceeded = True
                            break
                        except Exception as e:
                            # DiÄŸer hatalar - retry queue'ya ekle
                            retry_queue.append(idx)
                            completed_count += 1
                            pbar.update(1)
                
                if quota_exceeded:
                    break
                
                # Retry queue'dan tekrar dene (boÅŸ slot varsa) - quota kontrolÃ¼ ile
                while retry_queue and len(future_to_idx) < batch_size and next_index < count and not quota_exceeded:
                    idx = retry_queue.pop(0)
                    p_idx = idx % len(prompts)
                    future = executor.submit(
                        generate_single_ai_text, 
                        model, 
                        prompts[p_idx], 
                        lock, 
                        last_request_time, 
                        MIN_REQUEST_INTERVAL * 1.5  # Retry'da biraz daha uzun bekle
                    )
                    future_to_idx[future] = idx
                
                if quota_exceeded:
                    break
                
                # Yeni batch gÃ¶nder (boÅŸ slot varsa) - quota kontrolÃ¼ ile
                while len(future_to_idx) < batch_size and next_index < count and not quota_exceeded:
                    p_idx = next_index % len(prompts)
                    future = executor.submit(
                        generate_single_ai_text, 
                        model, 
                        prompts[p_idx], 
                        lock, 
                        last_request_time, 
                        MIN_REQUEST_INTERVAL
                    )
                    future_to_idx[future] = next_index
                    next_index += 1
                
                # KÄ±sa bekleme (CPU kullanÄ±mÄ±nÄ± azaltmak iÃ§in)
                if not future_to_idx:
                    break
                time.sleep(0.1)

    # Quota hatasÄ± kontrolÃ¼
    if quota_exceeded:
        # Final kayÄ±t (mevcut verileri kaydet)
        if len(ai_texts) > last_save_count:
            save_checkpoint(ai_texts)
        
        print(f"\n{'='*60}")
        print("âŒ API QUOTA LÄ°MÄ°TÄ° AÅILMIÅ - Ä°ÅLEM DURDURULDU")
        print(f"{'='*60}")
        print("\nâš  API quota limitiniz aÅŸÄ±lmÄ±ÅŸ gÃ¶rÃ¼nÃ¼yor.")
        print("   Bu durumda script Ã§alÄ±ÅŸmaya devam edemez.")
        print("\nğŸ“‹ Ã‡Ã–ZÃœM Ã–NERÄ°LERÄ°:")
        print("   1. BirkaÃ§ saat bekleyin (quota genelde saatlik/gÃ¼nlÃ¼k reset olur)")
        print("   2. Google Cloud Console'dan quota durumunuzu kontrol edin")
        print("   3. API planÄ±nÄ±zÄ± yÃ¼kseltmeyi dÃ¼ÅŸÃ¼nÃ¼n")
        print(f"\nğŸ’¾ MEVCUT DURUM:")
        print(f"   - Toplanan veri: {len(ai_texts)} adet")
        print(f"   - Checkpoint dosyasÄ±: {CHECKPOINT_FILE}")
        print(f"   - Veriler gÃ¼vende, quota reset olduktan sonra kaldÄ±ÄŸÄ± yerden devam edebilirsiniz")
        print(f"\n{'='*60}\n")
        return ai_texts  # Mevcut verileri dÃ¶ndÃ¼r
    
    # Final kayÄ±t
    if len(ai_texts) > last_save_count:
        save_checkpoint(ai_texts)
    
    print(f"\nâœ“ Toplam {len(ai_texts)} AI metni Ã¼retildi.")
    if len(ai_texts) < count:
        print(f"âš  Hedef: {count}, Ãœretilen: {len(ai_texts)} (Fark: {count - len(ai_texts)})")
        if retry_queue:
            print(f"âš  {len(retry_queue)} istek baÅŸarÄ±sÄ±z oldu ve retry edilemedi.")
    
    return ai_texts

def save_data(data: List[Dict], filename: str):
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # JSON
    json_path = os.path.join(OUTPUT_DIR, f"{filename}.json")
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    # CSV (Opsiyonel, hata verirse program durmasÄ±n)
    try:
        df = pd.DataFrame(data)
        csv_path = os.path.join(OUTPUT_DIR, f"{filename}.csv")
        df.to_csv(csv_path, index=False, encoding='utf-8')
    except Exception as e:
        print(f"CSV kaydÄ± yapÄ±lamadÄ±: {e}")
        
    print(f"âœ“ {filename} baÅŸarÄ±yla kaydedildi.")

def load_checkpoint() -> List[Dict]:
    """
    Mevcut AI verilerini yÃ¼kler. Ã–ncelik sÄ±rasÄ±:
    1. Checkpoint dosyasÄ±
    2. ai_abstracts.json
    3. combined_dataset.csv'den AI verileri (eÄŸer varsa)
    """
    # 1. Ã–nce checkpoint dosyasÄ±nÄ± kontrol et
    if os.path.exists(CHECKPOINT_FILE):
        try:
            with open(CHECKPOINT_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if data:
                    print(f"âœ“ Checkpoint yÃ¼klendi: {len(data)} adet mevcut veri bulundu")
                return data
        except Exception as e:
            print(f"âš  Checkpoint yÃ¼klenirken hata: {e}")
    
    # 2. Checkpoint yoksa, mevcut ai_abstracts.json'dan yÃ¼kle (eÄŸer varsa)
    ai_abstracts_file = os.path.join(OUTPUT_DIR, "ai_abstracts.json")
    if os.path.exists(ai_abstracts_file):
        try:
            with open(ai_abstracts_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if data:
                    print(f"âœ“ Mevcut AI verileri yÃ¼klendi: {len(data)} adet (ai_abstracts.json'dan)")
                    # Checkpoint dosyasÄ±nÄ± geri oluÅŸtur
                    save_checkpoint(data)
                    print(f"âœ“ Checkpoint dosyasÄ± geri oluÅŸturuldu")
                return data
        except Exception as e:
            print(f"âš  AI verileri yÃ¼klenirken hata: {e}")
    
    # 3. JSON yoksa, combined_dataset.csv'den AI verilerini yÃ¼kle
    combined_csv = os.path.join(OUTPUT_DIR, "combined_dataset.csv")
    if os.path.exists(combined_csv):
        try:
            import pandas as pd
            df = pd.read_csv(combined_csv)
            ai_data = df[df['label'] == 'AI'].to_dict('records')
            if ai_data:
                # CSV'den gelen verileri JSON formatÄ±na Ã§evir
                formatted_data = []
                for row in ai_data:
                    formatted_data.append({
                        "text": row.get('text', ''),
                        "label": "AI",
                        "source": row.get('source', 'gemini'),
                        "prompt": row.get('prompt', ''),
                        "generated_date": row.get('generated_date', '')
                    })
                print(f"âœ“ Mevcut AI verileri yÃ¼klendi: {len(formatted_data)} adet (combined_dataset.csv'den)")
                # Checkpoint dosyasÄ±nÄ± oluÅŸtur
                save_checkpoint(formatted_data)
                print(f"âœ“ Checkpoint dosyasÄ± oluÅŸturuldu")
                return formatted_data
        except Exception as e:
            print(f"âš  CSV'den veri yÃ¼klenirken hata: {e}")
    
    return []

def save_checkpoint(data: List[Dict]):
    try:
        with open(CHECKPOINT_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except:
        pass

def main():
    # 1. Human verilerini kontrol et
    human_abstracts = load_human_abstracts()
    if not human_abstracts:
        return

    # 2. AI Verisi Ãœret
    ai_texts = generate_ai_texts(AI_COUNT, GEMINI_API_KEY, MAX_WORKERS)
    
    # 3. AI verilerini ayrÄ± dosyaya kaydet (her zaman)
    if ai_texts:
        print(f"\n{'='*60}")
        print("AI VERÄ°LERÄ° KAYDEDÄ°LÄ°YOR")
        print(f"{'='*60}\n")
        save_data(ai_texts, "ai_abstracts")
        
        # 4. BirleÅŸtirilmiÅŸ veri seti oluÅŸtur ve kaydet
        print(f"\n{'='*60}")
        print("BÄ°RLEÅTÄ°RÄ°LMÄ°Å VERÄ° SETÄ° OLUÅTURULUYOR")
        print(f"{'='*60}\n")
        all_data = human_abstracts + ai_texts
        save_data(all_data, "combined_dataset")
        
        # 5. Temizlik - Sadece tÃ¼m iÅŸlem tamamlandÄ±ÄŸÄ±nda checkpoint'i sil
        if len(ai_texts) >= AI_COUNT:
            if os.path.exists(CHECKPOINT_FILE):
                os.remove(CHECKPOINT_FILE)
                print(f"\nâœ“ Checkpoint dosyasÄ± temizlendi (tÃ¼m veriler toplandÄ±)")
        else:
            print(f"\nâš  Checkpoint dosyasÄ± korunuyor (kaldÄ±ÄŸÄ± yerden devam iÃ§in)")
            print(f"   - Mevcut: {len(ai_texts)}/{AI_COUNT} AI verisi")
            print(f"   - Checkpoint: {CHECKPOINT_FILE}")
        
        # Ä°statistikler
        print(f"\n{'='*60}")
        print("TOPLAMA Ä°STATÄ°STÄ°KLERÄ°")
        print("=" * 60)
        print(f"Ä°nsan yazÄ±mÄ± Ã¶rnekler: {len(human_abstracts)}")
        print(f"AI yazÄ±mÄ± Ã¶rnekler: {len(ai_texts)}")
        print(f"Toplam Ã¶rnek: {len(all_data)}")
        print(f"Veri seti kaydedildi: {OUTPUT_DIR}")
        print("=" * 60)

if __name__ == "__main__":
    main()
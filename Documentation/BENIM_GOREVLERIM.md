# ðŸ“‹ Benim GÃ¶revlerim - TextHunter Projesi

## ðŸŽ¯ Proje Ã–zeti

**Proje AdÄ±:** Human or AI - Makale Ã–zetleri Ãœzerinden Metin Tespiti  
**Proje Teslimi:** 19 AralÄ±k 2025 veya 26 AralÄ±k 2025  
**DÃ¶nem Notuna Etkisi:** %40

---

## ðŸ‘¨â€ðŸ’» Bana DÃ¼ÅŸen GÃ¶revler

| User Story | GÃ¶rev | Puan | Durum |
|------------|-------|------|-------|
| **US-1** | Veri Seti Toplama | 5 puan | âœ… TamamlandÄ± |
| **US-2** | Veri Temizleme (EDA) | 5 puan | â³ Devam Ediyor |
| **US-3** | Model EÄŸitimi (3 farklÄ± ML) | 10 puan | ðŸ”„ HazÄ±r |
| - | White Box Testler | - | ðŸ“ YapÄ±lacak |
| - | Kod Kalite Analizi (SonarQube) | - | ðŸ“ YapÄ±lacak |

**Toplam Puan:** 20 puan (maksimum)

---

## ðŸ“ User Story-1: Veri Seti Toplama (5 Puan) âœ…

### Gereksinimler
- âœ… En az 6000 Ã¶rnek veri
- âœ… 3000 insan yazÄ±mÄ± makale Ã¶zeti
- âœ… 3000 AI (Gemini) yazÄ±mÄ± metin
- âœ… ArXiv sitesinden veri toplama
- âœ… Uygun lisans kontrolÃ¼ (MIT, Apache 2.0, BSD, CC-BY, CC0)

### Mevcut Durum
```
ðŸ“Š Veri Ä°statistikleri:
- Toplam Ã–rnek: ~19.472
- Human Ã–rnekleri: YÃ¼klendi âœ…
- AI Ã–rnekleri: YÃ¼klendi âœ…
- Format: CSV ve JSON
```

### Ä°lgili Dosyalar
| Dosya | AÃ§Ä±klama |
|-------|----------|
| `Scripts/data_collection.py` | Ana veri toplama scripti |
| `Scripts/data_collection/collect_arxiv_data.py` | ArXiv'den veri toplama |
| `Scripts/generate_ai_data.py` | Gemini AI ile metin Ã¼retimi |
| `Data/raw/combined_dataset.csv` | BirleÅŸtirilmiÅŸ veri seti |
| `Data/raw/human_abstracts.csv` | Ä°nsan yazÄ±mÄ± Ã¶zetler |
| `Data/raw/ai_abstracts.csv` | AI yazÄ±mÄ± metinler |

### NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?

```powershell
# 1. Gerekli paketleri yÃ¼kle
cd Scripts
pip install -r requirements.txt

# 2. Gemini API anahtarÄ±nÄ± ayarla
$env:GEMINI_API_KEY="your-api-key-here"

# 3. Veri toplama scriptini Ã§alÄ±ÅŸtÄ±r
python data_collection.py
```

---

## ðŸ“ User Story-2: Veri Temizleme / EDA (5 Puan) â³

### Gereksinimler
- â³ Veri temizleme (null deÄŸerler, duplikasyonlar)
- â³ Metin normalizasyonu
- â³ EDA (Exploratory Data Analysis)
- â³ Veri dengeleme

### Ä°lgili Dosyalar
| Dosya | AÃ§Ä±klama |
|-------|----------|
| `Scripts/data_cleaning.py` | Veri temizleme scripti |
| `Data/cleaned/` | TemizlenmiÅŸ veri klasÃ¶rÃ¼ |

### NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?

```powershell
cd Scripts
python data_cleaning.py
```

### Temizleme Ä°ÅŸlemleri

1. **Metin Normalizasyonu:**
   - KÃ¼Ã§Ã¼k harfe Ã§evirme
   - URL'leri kaldÄ±rma
   - Email adreslerini kaldÄ±rma
   - Fazla boÅŸluklarÄ± temizleme

2. **Duplikasyon KontrolÃ¼:**
   - Tekrarlanan metinleri kaldÄ±rma
   - Benzersiz metin kontrolÃ¼

3. **Veri DoÄŸrulama:**
   - Minimum metin uzunluÄŸu: 50 karakter
   - Maksimum metin uzunluÄŸu: 5000 karakter
   - Label kontrolÃ¼ (Human/AI)

4. **Veri Dengeleme:**
   - Human ve AI sÄ±nÄ±flarÄ±nÄ± eÅŸitleme

### EDA (Exploratory Data Analysis) Ä°Ã§in YapÄ±lacaklar

```python
# EDA iÃ§in Ã¶rnek kod
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Veri yÃ¼kle
df = pd.read_csv('../Data/raw/combined_dataset.csv')

# Temel istatistikler
print(df.describe())
print(df['label'].value_counts())

# Metin uzunluÄŸu daÄŸÄ±lÄ±mÄ±
df['text_length'] = df['text'].str.len()
plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='text_length', hue='label', bins=50)
plt.title('Metin UzunluÄŸu DaÄŸÄ±lÄ±mÄ±')
plt.savefig('../Documentation/eda_text_length.png')

# Word count daÄŸÄ±lÄ±mÄ±
df['word_count'] = df['text'].str.split().str.len()
plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='word_count', hue='label', bins=50)
plt.title('Kelime SayÄ±sÄ± DaÄŸÄ±lÄ±mÄ±')
plt.savefig('../Documentation/eda_word_count.png')
```

---

## ðŸ“ User Story-3: Model EÄŸitimi (10 Puan) ðŸ”„

### Gereksinimler
- âœ… 3 farklÄ± ML algoritmasÄ± ile model eÄŸitimi
- âœ… Naive Bayes modeli
- âœ… Random Forest modeli
- âœ… SVM modeli

### EÄŸitilecek Modeller

| Model | Vectorizer | AÃ§Ä±klama |
|-------|------------|----------|
| Naive Bayes | BoW | Bag of Words ile Naive Bayes |
| Naive Bayes | TF-IDF | TF-IDF ile Naive Bayes |
| Random Forest | BoW | Bag of Words ile Random Forest |
| Random Forest | TF-IDF | TF-IDF ile Random Forest |
| SVM | BoW | Bag of Words ile SVM |
| SVM | TF-IDF | TF-IDF ile SVM |

### Ä°lgili Dosyalar
| Dosya | AÃ§Ä±klama |
|-------|----------|
| `Scripts/train_models.py` | Model eÄŸitim scripti |
| `MLModels/` | EÄŸitilmiÅŸ modeller klasÃ¶rÃ¼ |

### NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?

```powershell
cd Scripts
python train_models.py
```

### EÄŸitim Ã‡Ä±ktÄ±larÄ±
EÄŸitim sonrasÄ± `MLModels/` klasÃ¶rÃ¼nde:
- `naive_bayes_bow_model.pkl`
- `naive_bayes_bow_vectorizer.pkl`
- `naive_bayes_tfidf_model.pkl`
- `naive_bayes_tfidf_vectorizer.pkl`
- `random_forest_bow_model.pkl`
- `random_forest_bow_vectorizer.pkl`
- `random_forest_tfidf_model.pkl`
- `random_forest_tfidf_vectorizer.pkl`
- `svm_bow_model.pkl`
- `svm_bow_vectorizer.pkl`
- `svm_tfidf_model.pkl`
- `svm_tfidf_vectorizer.pkl`
- `training_results.json` (EÄŸitim metrikleri)

### Model Performans Metrikleri

Her model iÃ§in kaydedilen metrikler:
- **Accuracy:** DoÄŸruluk oranÄ±
- **Precision:** Kesinlik
- **Recall:** DuyarlÄ±lÄ±k
- **F1-Score:** F1 skoru
- **Confusion Matrix:** KarÄ±ÅŸÄ±klÄ±k matrisi

---

## ðŸ§ª White Box Testler

### Test DosyasÄ± Konumu
- `Tests/` klasÃ¶rÃ¼
- `Documentation/WHITE_BOX_TESTLER.md`

### YapÄ±lacak Test TÃ¼rleri

1. **Statement Coverage (Deyim Kapsama):**
   - Her kod satÄ±rÄ±nÄ±n en az bir kez Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ±
   
2. **Branch Coverage (Dal Kapsama):**
   - Her if/else dalÄ±nÄ±n test edilmesi
   
3. **Path Coverage (Yol Kapsama):**
   - FarklÄ± kod yollarÄ±nÄ±n test edilmesi

### Test Edilecek Fonksiyonlar

```python
# data_cleaning.py
- clean_text()
- remove_duplicates()
- balance_dataset()
- validate_data()

# train_models.py
- load_data()
- train_naive_bayes()
- train_random_forest()
- train_svm()
```

### Ã–rnek Test Kodu

```python
import pytest
from Scripts.data_cleaning import clean_text, remove_duplicates

class TestDataCleaning:
    def test_clean_text_removes_urls(self):
        text = "Check this https://example.com link"
        result = clean_text(text)
        assert "https://" not in result
    
    def test_clean_text_removes_emails(self):
        text = "Contact test@email.com for info"
        result = clean_text(text)
        assert "@" not in result
    
    def test_clean_text_short_text_returns_empty(self):
        text = "Short"
        result = clean_text(text)
        assert result == ""
    
    def test_remove_duplicates(self):
        data = [
            {"text": "Same text"},
            {"text": "Same text"},
            {"text": "Different text"}
        ]
        result = remove_duplicates(data)
        assert len(result) == 2
```

---

## ðŸ“Š Kod Kalite Analizi (SonarQube)

### SonarQube Kurulumu

```powershell
# SonarQube Docker ile Ã§alÄ±ÅŸtÄ±rma
docker run -d --name sonarqube -p 9000:9000 sonarqube:latest

# SonarScanner kurulumu
# https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/
```

### sonar-project.properties

```properties
sonar.projectKey=texthunter
sonar.projectName=TextHunter
sonar.projectVersion=1.0
sonar.sources=.
sonar.sourceEncoding=UTF-8
sonar.language=py,cs
sonar.python.version=3.11
```

### Analiz Ã‡alÄ±ÅŸtÄ±rma

```powershell
sonar-scanner
```

### Kontrol Edilecek Metrikler
- **Code Smells:** Kod kokularÄ±
- **Bugs:** Hata sayÄ±sÄ±
- **Vulnerabilities:** GÃ¼venlik aÃ§Ä±klarÄ±
- **Code Coverage:** Test kapsama oranÄ±
- **Duplications:** Tekrarlanan kod yÃ¼zdesi

---

## ðŸ“… Ä°ÅŸ PlanÄ± / Timeline

### Hafta 1 (Mevcut)
- [x] Veri seti toplama
- [x] Temel proje yapÄ±sÄ±
- [ ] Veri temizleme
- [ ] EDA

### Hafta 2
- [ ] Model eÄŸitimi
- [ ] White box testler
- [ ] Kod kalite analizi

### Teslim Ã–ncesi
- [ ] DokÃ¼mantasyon kontrolÃ¼
- [ ] Test sonuÃ§larÄ±
- [ ] Final kontrol

---

## ðŸ”— ArkadaÅŸÄ±ma DÃ¼ÅŸen GÃ¶revler (Referans)

| User Story | GÃ¶rev | Puan |
|------------|-------|------|
| US-4 | Model Entegrasyonu | 10 puan |
| US-5 | SonuÃ§ GÃ¶sterimi (3 model, yÃ¼zdeler) | 10 puan |
| - | ArayÃ¼z (UI) | - |
| - | DokÃ¼mantasyon Paketi | - |
| - | Test Cases | - |

**Not:** Ã‡oklu model desteÄŸi olmazsa -5 puan!

---

## ðŸ“ Notlar

### API AnahtarÄ±
Gemini API anahtarÄ± iÃ§in: https://makersuite.google.com/app/apikey

### Gerekli Paketler
```
requests>=2.31.0
beautifulsoup4>=4.12.0
arxiv>=2.1.0
google-generativeai>=0.3.0
pandas>=2.0.0
numpy>=1.24.0
tqdm>=4.66.0
scikit-learn>=1.3.0
joblib>=1.3.0
nltk>=3.8.0
```

### Proje YapÄ±sÄ±
```
TextHunter/
â”œâ”€â”€ Scripts/                 # Python scriptleri (BENÄ°M)
â”‚   â”œâ”€â”€ data_collection.py   # Veri toplama
â”‚   â”œâ”€â”€ data_cleaning.py     # Veri temizleme
â”‚   â””â”€â”€ train_models.py      # Model eÄŸitimi
â”œâ”€â”€ Data/                    # Veri klasÃ¶rleri
â”‚   â”œâ”€â”€ raw/                 # Ham veri
â”‚   â”œâ”€â”€ cleaned/             # TemizlenmiÅŸ veri
â”‚   â””â”€â”€ processed/           # Ä°ÅŸlenmiÅŸ veri
â”œâ”€â”€ MLModels/                # EÄŸitilmiÅŸ modeller
â”œâ”€â”€ Tests/                   # Testler
â”œâ”€â”€ Documentation/           # DokÃ¼mantasyon
â”œâ”€â”€ Controllers/             # ASP.NET Controller'lar (ARKADAÅž)
â”œâ”€â”€ Views/                   # Razor Views (ARKADAÅž)
â””â”€â”€ Services/               # ML Servisler (ARKADAÅž)
```

---

**Son GÃ¼ncelleme:** 17 AralÄ±k 2025

